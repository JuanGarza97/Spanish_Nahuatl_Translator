{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanGarza97/Spanish_Nahuatl_Translator/blob/main/Avance5_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AVANCE 5. MODELO FINAL**"
      ],
      "metadata": {
        "id": "3SWMOauDj0bD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nombre del Trabajo:\n",
        "AI for Good: Human Heritage\n",
        "Automatic pre-Hispanic to Spanish Recogniser and Translator\n",
        "\n",
        "\n",
        "Nombre del asesor del proyecto: Dr. Juan Arturo Nolazco Flores\n",
        "\n",
        "Equipo: 20\n",
        "Nombre de alumnos:\n",
        " * Juan Carlos Garza Sanchez\tA00821522\n",
        " * Sinaí Avalos Rivera \t\t\tA01730466"
      ],
      "metadata": {
        "id": "h4n4LM9ljlSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FEW-SHOTS LEARNING**"
      ],
      "metadata": {
        "id": "W5g4X0U4pv5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este proyecto tiene como objetivo evaluar y comparar el desempeño de dos modelos de traducción automática, Gemini y Llama3, en la tarea de traducción de oraciones en una lengua indígena a su correspondiente en español.\n",
        "\n",
        "Luego evalúa esa traducción utilizando las métricas METEOR, BLEU y ROUGE. Se eligieron estos modelos debido a que son de uso gratuito y son ampliamente utilizados para few shots learning.\n",
        "\n",
        "Este modelo, incluye la comparación y análisis de cómo los shots o el número de ejemplos de referencia proporcionados a los modelos afectan el rendimiento de los modelos, por lo que se realiza un análisis comparativo para identificar qué tan bien cado uno se adapta a la lingüiística."
      ],
      "metadata": {
        "id": "SZ3uL6XUjalb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los modelos de ensamble son populares en tareas de aprendizaje automático debido a su capacidad para combinar varios modelos base y mejorar el rendimiento general. Sin embargo, en este proyecto específico de traducción automática, se presentan las siguientes razones por las cuales los modelos de ensamble no pueden ser considerados:\n",
        "\n",
        "* Alta complejidad computacional: Debido a que combinan los resultados de varios modelos base, lo que significa que la carga computacional se incrementa significativamente. Esto no solo aumentaría el tiempo necesario para realizar las inferencias, sino también la memoria y los recursos de procesamiento requeridos.\n",
        "\n",
        "* Pérdida de interpretabilidad: Uno de los beneficios de trabajar con modelos individuales como Gemini y Llama3 es que se pueden analizar y comprender más fácilmente sus decisiones y desempeño.\n",
        "\n",
        "* Desempeño no garantizado: Aunque  pueden mejorar el desempeño en algunas tareas, en otros casos, no siempre logran superar el rendimiento de un modelo individual bien entrenado, especialmente en dominios específicos como la traducción automática.\n",
        "\n",
        "* Limitación en la generalización: Para lenguas poco representadas o complejas como la que se traduce en este proyecto, los modelos base deben tener un alto nivel de conocimiento sobre la lengua y las estructuras lingüísticas involucradas.\n",
        "\n",
        "* Disponibilidad de modelos base optimizados: En lugar de combinar varios modelos que podrían estar menos especializados en el dominio o la lengua, se puede optar por un modelo base de alto rendimiento, como los utilizados en este proyecto (Gemini y Llama3), que han sido entrenados y afinados para tareas de traducción específica, maximizando así la precisión y efectividad."
      ],
      "metadata": {
        "id": "HVWmVL-8SrUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "134eDCoHeD8_",
        "outputId": "63c69f80-2441-47c1-94ce-239c30f5379c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.11/dist-packages (1.79.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.11/dist-packages (3.8.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (4.67.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.24.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (4.25.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (24.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (3.29.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.27.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-aiplatform nltk==3.8.1 rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "# Recursos de NLTK para tokenizacion y WordNet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.tokenize import word_tokenize\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "\n",
        "from huggingface_hub import InferenceClient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlKbt-uzApwQ",
        "outputId": "85e91eee-8da7-4fab-bc27-0bd57d9e862a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar dataset\n",
        "df = pd.read_csv(\"hf://datasets/somosnlp-hackathon-2022/Axolotl-Spanish-Nahuatl/train.csv\")\n",
        "df = df[['sp', 'nah']].rename(columns={'sp': 'spanish', 'nah': 'nahuatl'})\n",
        "df = df.dropna(axis=0, how='any')\n",
        "df = df.astype(str)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "3fWzoGALeJCf",
        "outputId": "a7b7a9cd-fcd6-4564-f870-5338828d755f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 spanish  \\\n",
              "0      Y así, cuando hizo su ofrenda de fuego, se sie...   \n",
              "1      ¿Si es jade, si es oro, acaso no tendrá que ir...   \n",
              "2      Y cuando el Sol estuvo solo en el cielo, enseg...   \n",
              "3      Allá acudieron asimismo los señores del cabild...   \n",
              "4                                                  Usos:   \n",
              "...                                                  ...   \n",
              "20023   El Espíritu y la esposa dicen: \"¡Ven!\"El que ...   \n",
              "20024   Yo advierto a todo el que oye las palabras de...   \n",
              "20025   y si alguno quita de las palabras del libro d...   \n",
              "20026   El que da testimonio de estas cosas dice: \"¡S...   \n",
              "20027     La gracia de nuestro Señor Jesús sea con todos   \n",
              "\n",
              "                                                 nahuatl  \n",
              "0      Auh in ye yuhqui in on tlenamacac niman ye ic ...  \n",
              "1      ¿In chalchihuitl, teocuitlatl, mach ah ca on yaz?  \n",
              "2      Auh yn oyuh in yoca hualmotlalli tonatiuh ylhu...  \n",
              "3      Yn oncan mohuicatza yhuan yn ciudad cabildo tl...  \n",
              "4                                               Kualtia:  \n",
              "...                                                  ...  \n",
              "20023  On Espíritu Santo niman isihuau on Borreguito ...  \n",
              "20024  Nemechtlachicahuilia nenmochimej yejhuan nenqu...  \n",
              "20025  Niman tla yacaj quipopolohuilis itemachtil Dio...  \n",
              "20026  On yejhuan quipantlantia yejhua in, ijquin qui...  \n",
              "20027  Ma toTeco Jesucristo mechtiochihua nenmochimej...  \n",
              "\n",
              "[20024 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13d6e229-23e7-4a74-83d8-11c061450ed9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spanish</th>\n",
              "      <th>nahuatl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Y así, cuando hizo su ofrenda de fuego, se sie...</td>\n",
              "      <td>Auh in ye yuhqui in on tlenamacac niman ye ic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>¿Si es jade, si es oro, acaso no tendrá que ir...</td>\n",
              "      <td>¿In chalchihuitl, teocuitlatl, mach ah ca on yaz?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Y cuando el Sol estuvo solo en el cielo, enseg...</td>\n",
              "      <td>Auh yn oyuh in yoca hualmotlalli tonatiuh ylhu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Allá acudieron asimismo los señores del cabild...</td>\n",
              "      <td>Yn oncan mohuicatza yhuan yn ciudad cabildo tl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Usos:</td>\n",
              "      <td>Kualtia:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20023</th>\n",
              "      <td>El Espíritu y la esposa dicen: \"¡Ven!\"El que ...</td>\n",
              "      <td>On Espíritu Santo niman isihuau on Borreguito ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20024</th>\n",
              "      <td>Yo advierto a todo el que oye las palabras de...</td>\n",
              "      <td>Nemechtlachicahuilia nenmochimej yejhuan nenqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20025</th>\n",
              "      <td>y si alguno quita de las palabras del libro d...</td>\n",
              "      <td>Niman tla yacaj quipopolohuilis itemachtil Dio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20026</th>\n",
              "      <td>El que da testimonio de estas cosas dice: \"¡S...</td>\n",
              "      <td>On yejhuan quipantlantia yejhua in, ijquin qui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20027</th>\n",
              "      <td>La gracia de nuestro Señor Jesús sea con todos</td>\n",
              "      <td>Ma toTeco Jesucristo mechtiochihua nenmochimej...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20024 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13d6e229-23e7-4a74-83d8-11c061450ed9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13d6e229-23e7-4a74-83d8-11c061450ed9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13d6e229-23e7-4a74-83d8-11c061450ed9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40545e74-c9d5-4924-b562-a957957e1d2f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40545e74-c9d5-4924-b562-a957957e1d2f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40545e74-c9d5-4924-b562-a957957e1d2f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6f534882-d927-45b2-b581-cece4b4a1fc6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6f534882-d927-45b2-b581-cece4b4a1fc6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20024,\n  \"fields\": [\n    {\n      \"column\": \"spanish\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18877,\n        \"samples\": [\n          \"\\u00bfQuieres a este muchacho?\",\n          \" Ahora bien, hermanos, vosotros sois hijos de la promesa tal como Isaac\",\n          \" Por la fe Abraham, cuando fue probado, ofreci\\u00f3 a Isaac.El que hab\\u00eda recibido las promesas ofrec\\u00eda a su hijo \\u00fanico\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nahuatl\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18942,\n        \"samples\": [\n          \"Tiyazque ye ichan\",\n          \"Auh inic onicpolo in tlacpac oncan no ninotlapololti auh nican nictlalia in huel neltiliztli in Maria Xoco yllamatzin in ipillo ytoca catca Anan Tlaco huecapa ypilo auh niman no hualla Miguel Ocelotl oquimonamicti Anan Tlaco auh niman oncan otlacat Maria Anan auh niman no quimonamictico in Pedro Luys chane Quauhchinanco zan ce in iconeuh oquichtli ytoca Estevan omomiquili auh cepa oquimonamictin yn itoca Magdalena auh niman no momiquili in Pedro Luys Quauhchinanco yc nictlalia nofirma Diego Leonardo escribano.\",\n          \"Amotlen mahuiztic.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar la API de Gemini\n",
        "GOOGLE_API_KEY = # Reemplazar con su KEY\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "gemini_model = genai.GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "9rhQMKjvCzlP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar la API de Hugging Face para Llama3\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=\"# Reemplazar con su KEY\")\n",
        "\n",
        "\n",
        "HF_API_KEY = \"# Reemplazar con su KEY\"\n",
        "# client = InferenceClient(model=\"meta-llama/Meta-Llama-3-8B\", token=HF_API_KEY)\n",
        "client = InferenceClient(model=\"meta-llama/Meta-Llama-3-8B-Instruct\", token=HF_API_KEY)"
      ],
      "metadata": {
        "id": "QFCcJd0fC59h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el prompt con un solo ejemplo\n",
        "def create_prompt(target_sentence, example):\n",
        "    return f\"\"\"\n",
        "    Translate the following Nahuatl sentence to Spanish:\n",
        "    Example:\n",
        "    \"{example['nahuatl'].values[0]}\" -> \"{example['spanish'].values[0]}\"\n",
        "\n",
        "    Now, translate this sentence:\n",
        "    \"{target_sentence}\"\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "NcfVYtA5C8us"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones de generación\n",
        "def gemini_generate(prompt):\n",
        "    response = gemini_model.generate_content(prompt)\n",
        "    return response.text.strip()"
      ],
      "metadata": {
        "id": "FSYB2amKDNLL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llama3_generate(prompt):\n",
        "    return client.text_generation(prompt, max_new_tokens=50).strip()"
      ],
      "metadata": {
        "id": "0hYm-bmjDO30"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación del modelo\n",
        "def evaluate_model(model_func, model_name, shots):\n",
        "    row = df.sample(n=1)\n",
        "    examples = df.sample(n=shots)\n",
        "    prompt = create_prompt(row['nahuatl'].values[0], examples)\n",
        "\n",
        "    prediction = model_func(prompt)\n",
        "    reference = row['spanish'].values[0]\n",
        "\n",
        "    # Evaluaciones\n",
        "    meteor = meteor_score([word_tokenize(reference)], word_tokenize(prediction))\n",
        "    smoother = SmoothingFunction().method4\n",
        "    bleu = sentence_bleu([word_tokenize(reference)], word_tokenize(prediction), weights=(0.5, 0.5), smoothing_function=smoother)\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "    rouge1 = scorer.score(reference, prediction)['rouge1'].fmeasure\n",
        "\n",
        "    return model_name, shots, meteor, bleu, rouge1"
      ],
      "metadata": {
        "id": "eGBCHo_EDRrn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregar las oraciones originales y traducidas a los resultados\n",
        "def evaluate_model_with_sentences(model_func, model_name, shots):\n",
        "    row = df.sample(n=1)\n",
        "    examples = df.sample(n=shots)\n",
        "    prompt = create_prompt(row['nahuatl'].values[0], examples)\n",
        "\n",
        "    prediction = model_func(prompt)\n",
        "    reference = row['spanish'].values[0]\n",
        "    original_sentence = row['nahuatl'].values[0]  # Oración original en Nahuatl\n",
        "\n",
        "    # Evaluaciones\n",
        "    meteor = meteor_score([word_tokenize(reference)], word_tokenize(prediction))\n",
        "    smoother = SmoothingFunction().method4\n",
        "    bleu = sentence_bleu([word_tokenize(reference)], word_tokenize(prediction), weights=(0.5, 0.5), smoothing_function=smoother)\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "    rouge1 = scorer.score(reference, prediction)['rouge1'].fmeasure\n",
        "\n",
        "    return model_name, shots, meteor, bleu, rouge1, original_sentence, prediction"
      ],
      "metadata": {
        "id": "172vV1JYOzHu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ejecutar pruebas con distintos shots\n",
        "shots_values = [1, 3, 5]\n",
        "models = [(gemini_generate, \"Gemini\"), (llama3_generate, \"Llama3\")]\n",
        "\n",
        "# Ejecutar pruebas con distintos shots y agregar oraciones originales y traducidas\n",
        "results_with_sentences = []\n",
        "for model_func, model_name in models:\n",
        "    for shots in shots_values:\n",
        "        results_with_sentences.append(evaluate_model_with_sentences(model_func, model_name, shots))"
      ],
      "metadata": {
        "id": "V6N12f9VGvY8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame con las columnas adicionales de oraciones originales y traducidas\n",
        "df_results = pd.DataFrame(results_with_sentences, columns=[\"Modelo\", \"Shots\", \"METEOR\", \"BLEU\", \"ROUGE-1\", \"Oración Original\", \"Traducción\"])\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL0No9FTGx3-",
        "outputId": "ed0a2d3a-9cc0-4d2a-8f49-631b15d0284a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Modelo  Shots    METEOR      BLEU   ROUGE-1  \\\n",
            "0  Gemini      1  0.222754  0.124541  0.237288   \n",
            "1  Gemini      3  0.199352  0.145138  0.313514   \n",
            "2  Gemini      5  0.316832  0.183494  0.309278   \n",
            "3  Llama3      1  0.000000  0.000000  0.000000   \n",
            "4  Llama3      3  0.070423  0.021507  0.000000   \n",
            "5  Llama3      5  0.170375  0.061859  0.207792   \n",
            "\n",
            "                                    Oración Original  \\\n",
            "0  Yejhuamej on yejhuan nemij quen tlanamactin, m...   \n",
            "1  36.\\tAhmo tle ye tihualmoxicoz, immicantla, im...   \n",
            "2  Auh quicacque yn Huitzillihuitzin yhuan yn Qua...   \n",
            "3  Sa no tejhuamej oticaquej on tlajtojli yejhuan...   \n",
            "4  Nima ye yc micalli, yc unca much tlamaque y me...   \n",
            "5  Yhuan cenca miec yn apachiuh yn acallac yn inc...   \n",
            "\n",
            "                                          Traducción  \n",
            "0  Y ellos vivieron como sabios, pero que no tuvi...  \n",
            "1  36.\\tNo hay nada en que nos podamos confiar, e...  \n",
            "2  Y dieron a Huitzilihuitl y a Cuatlecohuatzin y...  \n",
            "3  -> \"¿Qué es lo que se llama Teco? ¿Qué es lo q...  \n",
            "4  -> \"No hay más, no hay más, no hay más, no hay...  \n",
            "5  -> \"Los españoles son muy ricos, y tienen una ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EVALUACIÓN DE RESULTADOS:**\n",
        "\n",
        "Para evaluar estos resultados, vamos a analizar las métricas METEOR, BLEU, y ROUGE-1, y lo que cada una de ellas refleja en el contexto de las oraciones originales y traducidas:\n",
        "\n",
        "1. METEOR (Metric for Evaluation of Translation with Explicit ORdering):\n",
        "La METEOR mide la calidad de las traducciones considerando sinónimos y diferentes órdenes de las palabras.\n",
        "Valores altos indican una mejor correspondencia semántica entre la traducción y la referencia.\n",
        "\n",
        "* Gemini muestra un aumento en la puntuación de METEOR al aumentar los shots: de 0.22 con 1 shot a 0.32 con 5 shots. Esto indica que Gemini logra una mayor correspondencia semántica a medida que se le da más contexto.\n",
        "\n",
        "* Mientras que Llama3 tiene puntuaciones bajas en METEOR. A pesar de que mejora con más shots (de 0 con 1 shot a 0.17 con 5 shots), sigue siendo relativamente baja, lo que sugiere que Llama3 no está capturando bien el significado durante la traducción.\n",
        "\n",
        "2. BLEU (Bilingual Evaluation Understudy):\n",
        "Mide la precisión de n-gramas, enfocándose en qué tan bien las palabras de la traducción coinciden con las de la referencia.\n",
        "Valores altos indican que la traducción tiene un gran solapamiento en términos de secuencia de palabras.\n",
        "\n",
        "* Gemini también muestra un aumento en BLEU con más shots: de 0.12 con 1 shot a 0.18 con 5 shots. Sin embargo, sus valores siguen siendo relativamente bajos, lo que sugiere que la traducción es algo diferente de la referencia, pero con algo de coincidencia.\n",
        "\n",
        "* Llama3, al igual que con METEOR, muestra un bajo desempeño en BLEU, con valores cercanos a 0. Esto sugiere que la traducción generada no es muy precisa en términos de las secuencias de palabras.\n",
        "\n",
        "3. ROUGE-1 (Recall-Oriented Understudy for Gisting Evaluation):\n",
        "ROUGE-1 mide la recuperación de n-gramas unigram, lo que indica qué tan bien las palabras clave de la traducción coinciden con las de la referencia.\n",
        "Valores altos indican que la traducción es capaz de recuperar correctamente las palabras clave de la referencia.\n",
        "\n",
        "* Gemini muestra mejoras con más shots, pasando de 0.24 con 1 shot a 0.31 con 3 shots, y luego se estabiliza con 5 shots. Esto indica que Gemini es consistente en la recuperación de palabras clave, con un rendimiento ligeramente mejor con más contexto.\n",
        "\n",
        "* Llama3, por otro lado, tiene un puntaje bajo de ROUGE-1 en todos los casos, con una mejora pequeña de 0.00 con 1 shot a 0.21 con 5 shots. Aunque mejora ligeramente, aún no logra una buena recuperación de palabras clave de la referencia."
      ],
      "metadata": {
        "id": "5QQf4-U-C23a"
      }
    }
  ]
}